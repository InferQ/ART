[**ART Framework Component Reference**](../README.md)

***

[ART Framework Component Reference](../README.md) / OpenRouterAdapter

# Class: OpenRouterAdapter

Defined in: [src/integrations/reasoning/openrouter.ts:141](https://github.com/hashangit/ART/blob/4b6e07b019bda196c951a1bba064e95e97bd080e/src/integrations/reasoning/openrouter.ts#L141)

Adapter for OpenRouter, which acts as a proxy to a wide variety of models.

## Implements

- [`ProviderAdapter`](../interfaces/ProviderAdapter.md)

## Constructors

### Constructor

> **new OpenRouterAdapter**(`options`): `OpenRouterAdapter`

Defined in: [src/integrations/reasoning/openrouter.ts:149](https://github.com/hashangit/ART/blob/4b6e07b019bda196c951a1bba064e95e97bd080e/src/integrations/reasoning/openrouter.ts#L149)

#### Parameters

##### options

[`OpenRouterAdapterOptions`](../interfaces/OpenRouterAdapterOptions.md)

#### Returns

`OpenRouterAdapter`

## Properties

### providerName

> `readonly` **providerName**: `"openrouter"` = `'openrouter'`

Defined in: [src/integrations/reasoning/openrouter.ts:142](https://github.com/hashangit/ART/blob/4b6e07b019bda196c951a1bba064e95e97bd080e/src/integrations/reasoning/openrouter.ts#L142)

The unique identifier name for this provider (e.g., 'openai', 'anthropic').

#### Implementation of

[`ProviderAdapter`](../interfaces/ProviderAdapter.md).[`providerName`](../interfaces/ProviderAdapter.md#providername)

## Methods

### call()

> **call**(`prompt`, `options`): `Promise`\<`AsyncIterable`\<[`StreamEvent`](../interfaces/StreamEvent.md), `any`, `any`\>\>

Defined in: [src/integrations/reasoning/openrouter.ts:164](https://github.com/hashangit/ART/blob/4b6e07b019bda196c951a1bba064e95e97bd080e/src/integrations/reasoning/openrouter.ts#L164)

Executes a call to the configured Large Language Model (LLM).
This method is typically implemented by a specific `ProviderAdapter`.
When streaming is requested via `options.stream`, it returns an AsyncIterable
that yields `StreamEvent` objects as they are generated by the LLM provider.
When streaming is not requested, it should still return an AsyncIterable
that yields a minimal sequence of events (e.g., a single TOKEN event with the full response,
a METADATA event if available, and an END event).

#### Parameters

##### prompt

[`ArtStandardPrompt`](../type-aliases/ArtStandardPrompt.md)

The prompt to send to the LLM, potentially formatted specifically for the provider.

##### options

[`CallOptions`](../interfaces/CallOptions.md)

Options controlling the LLM call, including mandatory `threadId`, tracing IDs, model parameters (like temperature), streaming preference, and call context.

#### Returns

`Promise`\<`AsyncIterable`\<[`StreamEvent`](../interfaces/StreamEvent.md), `any`, `any`\>\>

A promise resolving to an AsyncIterable of `StreamEvent` objects.

#### Throws

If a critical error occurs during the initial call setup or if the stream itself errors out (typically code `LLM_PROVIDER_ERROR`).

#### Implementation of

[`ProviderAdapter`](../interfaces/ProviderAdapter.md).[`call`](../interfaces/ProviderAdapter.md#call)
